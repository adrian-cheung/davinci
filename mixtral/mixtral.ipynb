{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_HOME'] = '../../.cache/huggingface/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n",
      "Loading checkpoint shards: 100%|██████████| 19/19 [23:30<00:00, 74.24s/it]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "# quantization_config = BitsAndBytesConfig(\n",
    "#         load_in_4bit=True,\n",
    "#         bnb_4bit_quant_type=\"nf4\",\n",
    "#         bnb_4bit_compute_dtype=\"torch.float16\",\n",
    "# )\n",
    "\n",
    "model_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, load_in_4bit=True, device_map=\"auto\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"In the following image description, which keywords may show up as text in the image? If there are none, output <NONE>. Be concise.\"\n",
    "few_shot_captions = [\n",
    "    \"a swimming pool with a warning sign about no running\",\n",
    "    \"person reading Georgia Tech Times newspaper on couch, drinking a can of Cola soda, home background, warm lighting, high quality\",\n",
    "    \"funny cartoon cat draws mouse on board, digital art, trending on artstation\",\n",
    "]\n",
    "few_shot_keywords = [\n",
    "    \"[warning, no running]\",\n",
    "    \"[Georgia Tech Times, Cola]\",\n",
    "    \"<NONE>\",\n",
    "]\n",
    "\n",
    "few_shot_prompts = []\n",
    "for i in range(len(few_shot_captions)):\n",
    "    few_shot_prompts.append({\"role\": \"user\", \"content\": f\"{instruction} \\\"{few_shot_captions[i]}\\\"\"})\n",
    "    few_shot_prompts.append({\"role\": \"assistant\", \"content\": f\"keywords: {few_shot_keywords[i]}\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_keywords(caption):\n",
    "    prompt = few_shot_prompts + [{\"role\": \"user\", \"content\": f\"{instruction} \\\"{caption}\\\"\"}]\n",
    "    \n",
    "    input_ids = tokenizer.apply_chat_template(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "\n",
    "    outputs = model.generate(input_ids, max_new_tokens=20, pad_token_id=tokenizer.eos_token_id)\n",
    "    decoded = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    cleaned = decoded.rsplit('[/INST]', 1)[1]\n",
    "    if '[' in cleaned and ']' in cleaned:\n",
    "        cleaned = cleaned.split('[')[1].split(']')[0]\n",
    "        out_keywords = [word.strip() for word in cleaned.split(',')]\n",
    "    elif '<NONE>' in cleaned:\n",
    "        out_keywords = ['<NONE>']\n",
    "    else:\n",
    "        out_keywords = ''\n",
    "    return out_keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "in_caption = \"photograph of a street with a yield sign on the left and stop sign on right, with a dog painting happy birthday in center, golden hour lighting, beautiful sky, 4k\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yield', 'stop']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_keywords(in_caption)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "processes = 8\n",
    "data_size = 4908\n",
    "\n",
    "def extract_all_keywords(output_folder):\n",
    "    skipped = 0\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    with tqdm(total=data_size, desc='total') as pbar:\n",
    "        for foldername, _, filenames in os.walk('../data/laion-mini'):\n",
    "            if 'caption.txt' in filenames:\n",
    "                caption_file = os.path.join(foldername, 'caption.txt')\n",
    "                # this will be the number of this particular caption\n",
    "                caption_id = foldername.split('/')[-1]\n",
    "                caption_copy_location = os.path.join(output_folder, caption_id + '.txt')\n",
    "                if os.path.exists(caption_copy_location):\n",
    "                    skipped += 1\n",
    "                    pbar.update()\n",
    "                    continue\n",
    "                shutil.copy2(caption_file, caption_copy_location)\n",
    "\n",
    "                caption_content = None\n",
    "                keywords = \"\"\n",
    "                with open(caption_file, 'r', encoding=\"utf-8\") as f:\n",
    "                    caption_content = f.read()\n",
    "                    keywords = extract_keywords(caption_content)\n",
    "                f.close()\n",
    "                keyword_copy_location = os.path.join(output_folder, caption_id + '.key')\n",
    "                with open(keyword_copy_location, 'w', encoding=\"utf-8\") as file:\n",
    "                    file.write('\\n'.join(keywords))\n",
    "                file.close()\n",
    "            pbar.update()\n",
    "    print(f\"Skipped {skipped} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "total: 4922it [1:28:05,  1.07s/it]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 2159 files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "extract_all_keywords('../data/laion-mini-mixtral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:57<00:00,  1.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Bury My Heart At Wounded Knee'], ['Chesterton Humberts', 'Tower Bridge'], ['A Psychological Analysis', 'Delusion Rubrics'], ['Facebook', 'Timeline', 'Movie Maker'], '', ['Ginger', 'Baker', 'Airforce', 'Live', '1970'], ['Parcours VOD', 'marketing digital'], '', ['Name', 'Number'], ['Pelham'], ['Gamestop Gift Card'], ['James Madison', 'Founding Father'], ['ELDERS', 'BUNBURY'], '', '', '', ['Family Firm Institute', 'Fellow'], ['Regis Philbin', 'Mark Malkoff'], ['Coffee', 'Books', 'Social Justice'], ['August Osage County', 'Zach Theatre'], '', ['Authorize Net', 'Verified', 'Merchant'], [\"Don't\", 'Mess With', 'Princess'], ['Trd', 'Toyota', 'vinyl decals'], ['MINI', 'GPS', 'MAGNETIC CAR TRACKER'], ['CLUB BTT', 'ALGAIR N'], ['Dailyexpress', 'autore'], ['Sniper Ghost Warrior 2'], ['<NONE>'], ['Honor', 'Activewear'], ['Seduced', 'masseuse', 'Porn', 'Movie'], ['Outside', 'Print', 'Kindle'], ['Cheb Bilal', 'Ramadan', 'Le Meilleur'], ['Prong X', 'No', 'Absolutes'], ['Before and After', 'Roseellen Brown'], ['Magic City Part 2', 'MC MAGIC CD'], ['Emergency', 'American Red Cross'], ['Make Money', 'Online', 'Side Money'], [\"'90 Day Wrap Up'\"], ['D', 'McComb', 'Sons', 'Covington', 'Knolls'], '', ['Harvey Milk'], ['Math Gear Fast Subtraction Facts'], '', ['25', 'off', 'Tops', 'Torrid'], ['ByLITA', 'Break Room', 'Indoor Outdoor Use'], '', ['RE', 'MAX'], ['the World in 80 Days'], ['BEST BOYFRIEND', \"Men's\", 'Tank'], '', ['Grow Your Business Show', 'Surrey', 'Business Expo', 'Race Day'], ['History', 'Film', 'Moving Pictures', 'Study', 'Past'], ['JR Rivas', 'Facebook Ads for Real Estate'], ['Dana', 'Mission Bay'], ['Couverture', 'Grain de sable'], ['Nibe'], ['Eat', 'Leaf', 'Rectangle'], ['Touch the Brightest Star', 'Christie Matheson'], ['French Guiana'], ['You Are My Sunshine', 'The Hound', 'The Fox'], ['ORBEA'], ['BTEC', 'National', 'IT', 'Practitioners'], ['Simi Valley', 'addiction treatment center', \"United Drug 'Rehab Group'\"], [\"'The Spaghetti'\", 'West'], ['One Foot In The Gravy', 'Deadly Deli Mystery'], ['keep the change', 'filthy', 'animal', 'home alone', 'christmas'], ['JOST MACHINERY'], ['Challenge', 'Singleness', 'Bible', 'says', 'about'], ['Made in Canada'], ['Bob', 'Floor Covering'], '', ['Broken China Distress', 'Oxide Ink Pad'], ['Pavilions', 'Professional', 'Center'], ['Fiesta', 'Quinceaera', 'Ball Gowns'], ['LPG Greetings', 'Irish', 'Baby'], '', ['Jacobs', 'Creation', 'Nice', 'Monaco'], ['Gimme Some Sugar Playlist', 'Sweet Love'], ['Cara', 'Jana', 'Income', 'YouTube'], ['Be BOLD', 'Be FEARLESS', 'Be YOU'], ['Rancho'], '', ['Duets', 'Frank Sinatra'], ['Pinkey', 'Blackhead Off', 'Moisture Nose Mask'], ['S S', '18', 'Footwear', 'Accessories'], '', ['Duane', 'Dibley', 'dalleck'], ['Mechanics Lien Recorded'], ['Skylight', 'Arcadium 2'], '', ['Adjustable', 'Earth', 'Clamps'], ['Amazon Cloud Player'], '', ['The Execution Channel', 'Ken MacLeod'], ['The Silkworm', 'Cormoran Strike'], ['The', 'Reluctant', 'Cook'], ['ORVIS', 'New Zealand'], ['Greenstar Landscaping'], ['Elements Massage']]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "eval_root = Path('../eval')\n",
    "\n",
    "eval_in = eval_root / 'marioeval100.txt'\n",
    "eval_data = eval_in.read_text().splitlines()\n",
    "\n",
    "eval_keywords = []\n",
    "for line in tqdm(eval_data):\n",
    "    keywords = extract_keywords(line)\n",
    "    eval_keywords.append(keywords)\n",
    "print(eval_keywords)\n",
    "\n",
    "eval_data = [line.replace('\"', '').replace(\"'\", '') for line in eval_data]\n",
    "\n",
    "eval_out = eval_root / 'marioeval100mixtral.txt'\n",
    "with open(eval_out, 'w') as f:\n",
    "    for caption, keywords in zip(eval_data, eval_keywords):\n",
    "        if '<NONE>' not in keywords:\n",
    "            key_set = set(keywords)\n",
    "            while key_set:\n",
    "                keyword = key_set.pop()\n",
    "                if keyword in caption:\n",
    "                    caption = caption.replace(keyword, f'\"{keyword}\"')\n",
    "        f.write(caption)\n",
    "        f.write('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:miniforge3-mixtral]",
   "language": "python",
   "name": "conda-env-miniforge3-mixtral-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
